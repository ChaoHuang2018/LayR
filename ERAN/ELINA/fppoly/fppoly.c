/*
 *
 *  This source file is part of ELINA (ETH LIbrary for Numerical Analysis).
 *  ELINA is Copyright Â© 2019 Department of Computer Science, ETH Zurich
 *  This software is distributed under GNU Lesser General Public License Version 3.0.
 *  For more information, see the ELINA project website at:
 *  http://elina.ethz.ch
 *
 *  THE SOFTWARE IS PROVIDED "AS-IS" WITHOUT ANY WARRANTY OF ANY KIND, EITHER
 *  EXPRESS, IMPLIED OR STATUTORY, INCLUDING BUT NOT LIMITED TO ANY WARRANTY
 *  THAT THE SOFTWARE WILL CONFORM TO SPECIFICATIONS OR BE ERROR-FREE AND ANY
 *  IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE,
 *  TITLE, OR NON-INFRINGEMENT.  IN NO EVENT SHALL ETH ZURICH BE LIABLE FOR ANY     
 *  DAMAGES, INCLUDING BUT NOT LIMITED TO DIRECT, INDIRECT,
 *  SPECIAL OR CONSEQUENTIAL DAMAGES, ARISING OUT OF, RESULTING FROM, OR IN
 *  ANY WAY CONNECTED WITH THIS SOFTWARE (WHETHER OR NOT BASED UPON WARRANTY,
 *  CONTRACT, TORT OR OTHERWISE).
 *
 */

#include "backsubstitute.h"



fppoly_t* fppoly_of_abstract0(elina_abstract0_t* a)
{
  return (fppoly_t*)a->value;
}

elina_abstract0_t* abstract0_of_fppoly(elina_manager_t* man, fppoly_t* fp)
{
  elina_abstract0_t* r = malloc(sizeof(elina_abstract0_t));
  assert(r);
  r->value = fp;
  r->man = elina_manager_copy(man);
  return r;
}


static inline void fppoly_internal_free(fppoly_internal_t* pr)
{
    if (pr) {
	pr->funid = ELINA_FUNID_UNKNOWN;
	free(pr);
	pr = NULL;
    }
}


static inline fppoly_internal_t* fppoly_internal_alloc(void)
{
    fppoly_internal_t* pr = (fppoly_internal_t*)malloc(sizeof(fppoly_internal_t));
    pr->funid = ELINA_FUNID_UNKNOWN;
    pr->man = NULL;
    pr->funopt = NULL; 
    pr->min_denormal = ldexpl(1.0,-1074);
    pr->ulp = ldexpl(1.0,-52);
    return pr;
}


/* back pointer to our internal structure from the manager */
fppoly_internal_t* fppoly_init_from_manager(elina_manager_t* man, elina_funid_t funid)
{
	
    fppoly_internal_t* pr = (fppoly_internal_t*)man->internal;
    pr->funid = funid;
	
    if (!(pr->man)) pr->man = man;
	
    return pr;
}


elina_manager_t * fppoly_manager_alloc(void){
	void** funptr;
	fesetround(FE_UPWARD);
	fppoly_internal_t *pr = fppoly_internal_alloc();
	elina_manager_t *man = elina_manager_alloc("fppoly",/* Library name */
			"1.0", /* version */
			pr, /* internal structure */
			(void (*)(void*))fppoly_internal_free /* free function for internal */
			);
	funptr = man->funptr;
	funptr[ELINA_FUNID_FREE] = &fppoly_free;
	/* 3.Printing */
	funptr[ELINA_FUNID_FPRINT] = &fppoly_fprint;
	return man;
}


neuron_t *neuron_alloc(void){
	neuron_t *res =  (neuron_t *)malloc(sizeof(neuron_t));
	res->expr = NULL;
	res->lb = -INFINITY;
	res->ub = INFINITY;
	res->lexpr = NULL;
	res->uexpr = NULL;
	return res;
}

layer_t * create_layer(size_t size, layertype_t type, activation_type_t activation){
	layer_t *layer = (layer_t*)malloc(sizeof(layer_t));
	layer->dims = size;
	layer->type = type;
        layer->activation = activation;
	layer->neurons = (neuron_t**)malloc(size*sizeof(neuron_t*));
	size_t i;
	for(i=0; i < size; i++){
		layer->neurons[i] = neuron_alloc();
	}
	layer->h_t_inf = NULL;
	layer->h_t_sup = NULL;
	layer->c_t_inf = NULL;
	layer->c_t_sup = NULL;
	return layer;
}


void fppoly_from_network_input_box(fppoly_t *res, size_t intdim, size_t realdim, double *inf_array, double *sup_array){
	
	res->layers = NULL;
	res->numlayers = 0;
	res->lstm_index = 0;
	size_t num_pixels = intdim + realdim;
	res->input_inf = (double *)malloc(num_pixels*sizeof(double));
	res->input_sup = (double *)malloc(num_pixels*sizeof(double));
	res->input_lexpr = NULL;
	res->input_uexpr = NULL;
	size_t i;
	for(i=0; i < num_pixels; i++){
		res->input_inf[i] = -inf_array[i];
		res->input_sup[i] = sup_array[i];
	}
	res->num_pixels = num_pixels;
	res->out = NULL;
}


elina_abstract0_t * fppoly_from_network_input(elina_manager_t *man, size_t intdim, size_t realdim, double *inf_array, double *sup_array){
	fppoly_t * res = (fppoly_t *)malloc(sizeof(fppoly_t));
	fppoly_from_network_input_box(res, intdim, realdim, inf_array, sup_array);
	return abstract0_of_fppoly(man,res);
}

void fppoly_set_network_input_box(elina_manager_t *man, elina_abstract0_t* element, size_t intdim, size_t realdim, double *inf_array, double * sup_array){
    fppoly_t * res = fppoly_of_abstract0(element);
    size_t num_pixels = intdim + realdim;
    res->numlayers = 0;
    size_t i;
    for(i=0; i < num_pixels; i++){
        res->input_inf[i] = -inf_array[i];
        res->input_sup[i] = sup_array[i];
    }
}

elina_abstract0_t* fppoly_from_network_input_poly(elina_manager_t *man, size_t intdim, size_t realdim, double *inf_array, double *sup_array, 
                                                  double * lexpr_weights, double * lexpr_cst, size_t * lexpr_dim, double * uexpr_weights,
						  double * uexpr_cst, size_t * uexpr_dim, size_t expr_size){
	fppoly_t * res = (fppoly_t *)malloc(sizeof(fppoly_t));
	
	fppoly_from_network_input_box(res, intdim, realdim, inf_array, sup_array);
	size_t num_pixels = intdim + realdim;
	res->input_lexpr = (expr_t **)malloc(num_pixels*sizeof(expr_t *));
	res->input_uexpr = (expr_t **)malloc(num_pixels*sizeof(expr_t *));
	
	size_t i;
        double * tmp_weights = (double*)malloc(expr_size*sizeof(double));
	size_t * tmp_dim = (size_t*)malloc(expr_size*sizeof(size_t));
	
	for(i = 0; i < num_pixels; i++){
		
		size_t j;
		for(j=0; j < expr_size; j++){
			tmp_weights[j] = lexpr_weights[i*expr_size+j];
			tmp_dim[j] = lexpr_dim[i*expr_size+j];
		}
		res->input_lexpr[i] = create_sparse_expr(tmp_weights, lexpr_cst[i], tmp_dim, expr_size);
		sort_sparse_expr(res->input_lexpr[i]);
	//printf("w: %p %g %g %g cst: %g dim: %p %zu %zu %zu\n",lexpr_weights[i],lexpr_weights[i][0],lexpr_weights[i][1], lexpr_weights[i][2],lexpr_cst[i],lexpr_dim[i],lexpr_dim[i][0],lexpr_dim[i][1], lexpr_dim[i][2]);
		//expr_print(res->input_lexpr[i]);
		//fflush(stdout);
		for(j=0; j < expr_size; j++){
			tmp_weights[j] = uexpr_weights[i*expr_size+j];
			tmp_dim[j] = uexpr_dim[i*expr_size+j];
		}
		res->input_uexpr[i] = create_sparse_expr(tmp_weights, uexpr_cst[i], tmp_dim, expr_size);
		sort_sparse_expr(res->input_uexpr[i]);
	//	expr_print(res->input_uexpr[i]);
	//	fflush(stdout);
	}
	free(tmp_weights);
	free(tmp_dim);
	return abstract0_of_fppoly(man,res);	

}

void fppoly_alloc_first_layer(fppoly_t *fp, size_t size, layertype_t type, activation_type_t activation){
	layer_t *layer = create_layer(size, type, activation);
        fp->layers = (layer_t **)malloc(2000*sizeof(layer_t *));
	fp->layers[0] = layer;
	fp->numlayers = 1;
	return;
}

void fppoly_add_new_layer(fppoly_t *fp, size_t size, layertype_t type, activation_type_t activation){
	size_t numlayers = fp->numlayers;
	fp->layers[numlayers] = create_layer(size,type, activation);
	fp->numlayers++;
	return;
}




void ffn_handle_first_layer(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *cst, size_t size, size_t num_pixels, size_t *predecessors, activation_type_t activation, bool alloc,
			    fnn_op OP){
	//printf("start \n");
	//fflush(stdout);
	fppoly_t *res = fppoly_of_abstract0(abs);
	//printf("coming here\n");
	//fflush(stdout);
	
    if(alloc){
        fppoly_alloc_first_layer(res,size, FFN, activation);
    }
	fppoly_internal_t *pr = fppoly_init_from_manager(man, ELINA_FUNID_ASSIGN_LINEXPR_ARRAY);
	size_t i, j;
	
	//for(i=0; i < num_pixels; i++){
	//	elina_interval_print(itv[i]);
	//	printf("\n");
	//}	
	//fflush(stdout);
	neuron_t ** neurons = res->layers[0]->neurons;
	res->layers[0]->predecessors = predecessors;
	
	for(i=0; i < size; i++){
		neuron_t *neuron = neurons[i];
		//double * weight_i = weights[i];
		double cst_i = cst[i];
                if(OP==MUL){
			neuron->expr = create_sparse_expr(&cst_i, 0, &i, 1);
        	}
		else if(OP==SUB1){
			double coeff = -1;
			neuron->expr = create_sparse_expr(&coeff, cst_i, &i, 1);
		}
		else if(OP==SUB2){
			double coeff = 1;
			neuron->expr = create_sparse_expr(&coeff, -cst_i, &i, 1);
		}
        	else{
			double * weight_i = weights[i];
        		neuron->expr = create_dense_expr(weight_i,cst_i,num_pixels);
		}
		
		neuron->lb = compute_lb_from_expr(pr, neuron->expr,res,-1);
		neuron->ub = compute_ub_from_expr(pr, neuron->expr,res,-1);
	}
	
	//printf("return here\n");
	//fppoly_fprint(stdout,man,res,NULL);
	//fflush(stdout);
	return;	
}


void ffn_handle_first_relu_layer(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,   size_t size, size_t num_pixels, size_t *predecessors){
        ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, RELU, true, MATMULT);
}

void ffn_handle_first_sigmoid_layer(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
        ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, SIGMOID, true, MATMULT);
}


void ffn_handle_first_tanh_layer(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
        ffn_handle_first_layer(man, abs, weights, bias,  size, num_pixels, predecessors, TANH, true, MATMULT);
}


void ffn_handle_first_parabola_layer(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
        ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, PARABOLA, true, MATMULT);
}

void ffn_handle_first_log_layer(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
        ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, LOG, true, MATMULT);
}

void ffn_handle_first_sub_layer(elina_manager_t* man, elina_abstract0_t * abs,  double *cst, bool is_minuend, size_t size, size_t *predecessors){
	if(is_minuend==true){
		ffn_handle_first_layer(man, abs, NULL, cst, size, size, predecessors, NONE, true, SUB1);
	}
	else{
        	ffn_handle_first_layer(man, abs, NULL, cst, size, size, predecessors, NONE, true, SUB2);
	}
}

void ffn_handle_first_mul_layer(elina_manager_t* man, elina_abstract0_t * abs, double *bias,  size_t size, size_t *predecessors){
        ffn_handle_first_layer(man, abs, NULL, bias, size, size, predecessors, NONE, true, MUL);
}

void ffn_handle_first_relu_layer_no_alloc(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,   size_t size, size_t num_pixels, size_t *predecessors){
    ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, RELU, false, MATMULT);
}

void ffn_handle_first_sigmoid_layer_no_alloc(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
    ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, SIGMOID, false, MATMULT);
}


void ffn_handle_first_tanh_layer_no_alloc(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
    ffn_handle_first_layer(man, abs, weights, bias,  size, num_pixels, predecessors, TANH, false, MATMULT);
}


void ffn_handle_first_parabola_layer_no_alloc(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
    ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, PARABOLA, false, MATMULT);
}

void ffn_handle_first_log_layer_no_alloc(elina_manager_t* man, elina_abstract0_t * abs, double **weights, double *bias,  size_t size, size_t num_pixels, size_t *predecessors){
    ffn_handle_first_layer(man, abs, weights, bias, size, num_pixels, predecessors, LOG, false, MATMULT);
}

void ffn_handle_intermediate_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * cst, size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, activation_type_t activation, bool alloc, bool use_area_heuristic, fnn_op OP){
    //printf("ReLU start here %zu %zu\n",num_in_neurons,num_out_neurons);
    //fflush(stdout);
    fppoly_t *fp = fppoly_of_abstract0(element);
    size_t numlayers = fp->numlayers;
    if(alloc){
        fppoly_add_new_layer(fp,num_out_neurons, FFN, activation);
    }
    neuron_t **out_neurons = fp->layers[numlayers]->neurons;
    fp->layers[numlayers]->predecessors = predecessors;
	
    size_t i;
    for(i=0; i < num_out_neurons; i++){
        
        double cst_i = cst[i];
	if(OP==MUL){
		out_neurons[i]->expr = create_sparse_expr(&cst_i, 0, &i, 1);
        }
	else if(OP==SUB1){
		double coeff = -1;
		out_neurons[i]->expr = create_sparse_expr(&coeff, cst_i, &i, 1);
	}
	else if(OP==SUB2){
		double coeff = 1;
		out_neurons[i]->expr = create_sparse_expr(&coeff, -cst_i, &i, 1);
	}
        else{
		double * weight_i = weights[i];
        	out_neurons[i]->expr = create_dense_expr(weight_i,cst_i,num_in_neurons);
	}
    }
    update_state_using_previous_layers_parallel(man,fp,numlayers, use_area_heuristic);
    
    //printf("return here2\n");
    //fppoly_fprint(stdout,man,fp,NULL);
    //fflush(stdout);
    return;
}

void ffn_handle_intermediate_affine_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias,  num_out_neurons, num_in_neurons, predecessors, NONE,  true, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_relu_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, RELU, true, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_sigmoid_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, SIGMOID, true, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_tanh_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias,  num_out_neurons, num_in_neurons, predecessors, TANH, true, use_area_heuristic, MATMULT);
}


void ffn_handle_intermediate_sub_layer(elina_manager_t* man, elina_abstract0_t* element,  double * cst, bool is_minuend, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    if(is_minuend==true){
    	ffn_handle_intermediate_layer(man, element, NULL, cst,  num_in_neurons, num_in_neurons, predecessors, NONE, true, use_area_heuristic, SUB1);
    }
    else{
    	ffn_handle_intermediate_layer(man, element, NULL, cst,  num_in_neurons, num_in_neurons, predecessors, NONE, true, use_area_heuristic, SUB2);
    }
}

void ffn_handle_intermediate_mul_layer(elina_manager_t* man, elina_abstract0_t* element,  double * bias,  size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, NULL, bias,  num_in_neurons, num_in_neurons, predecessors, NONE, true, use_area_heuristic, MUL);
}


void ffn_handle_intermediate_parabola_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias, size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
	
    ffn_handle_intermediate_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, PARABOLA, true, use_area_heuristic, MATMULT);
	
}

void ffn_handle_intermediate_log_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias,  num_out_neurons, num_in_neurons, predecessors, LOG, true, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_affine_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias,  num_out_neurons, num_in_neurons, predecessors, NONE, false, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_relu_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, RELU, false, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_sigmoid_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, SIGMOID, false, use_area_heuristic, MATMULT);
}

void ffn_handle_intermediate_tanh_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias,  num_out_neurons, num_in_neurons, predecessors, TANH, false, use_area_heuristic, MATMULT);
}


void ffn_handle_intermediate_parabola_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias, size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    
    ffn_handle_intermediate_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, PARABOLA, false, use_area_heuristic, MATMULT);
    
}

void ffn_handle_intermediate_log_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool use_area_heuristic){
    ffn_handle_intermediate_layer(man, element, weights, bias,  num_out_neurons, num_in_neurons, predecessors, LOG, false, use_area_heuristic, MATMULT);
}




void handle_final_relu_layer(fppoly_internal_t *pr, output_abstract_t * out, neuron_t **neurons, size_t size, bool has_relu){
	size_t i;
        if(has_relu){
		for(i=0; i < size; i++){
			out->output_inf[i] = apply_relu_lexpr(pr,&out->lexpr[i],neurons[i]);
			out->output_sup[i] = apply_relu_uexpr(pr,&out->uexpr[i],neurons[i]);
		}
	}
	else{
		for(i=0; i < size; i++){
			out->output_inf[i] = neurons[i]->lb;
			out->output_sup[i] = neurons[i]->ub;
		}
	}	
}



void handle_final_sigmoid_layer(fppoly_internal_t *pr, output_abstract_t * out, neuron_t **neurons, size_t size, bool has_sigmoid){
	size_t i;
        if(has_sigmoid){
		for(i=0; i < size; i++){
			out->output_inf[i] = apply_sigmoid_lexpr(pr,&out->lexpr[i],neurons[i]);
			out->output_sup[i] = apply_sigmoid_uexpr(pr,&out->uexpr[i],neurons[i]);
		}
	}
	else{
		for(i=0; i < size; i++){
			out->output_inf[i] = neurons[i]->lb;
			out->output_sup[i] = neurons[i]->ub;
		}
	}	
}

void handle_final_tanh_layer(fppoly_internal_t *pr, output_abstract_t * out, neuron_t **neurons, size_t size, bool has_tanh){
	size_t i;
        if(has_tanh){
		for(i=0; i < size; i++){
			out->output_inf[i] = apply_tanh_lexpr(pr,&out->lexpr[i],neurons[i]);
			out->output_sup[i] = apply_tanh_uexpr(pr,&out->uexpr[i],neurons[i]);
		}
	}
	else{
		for(i=0; i < size; i++){
			out->output_inf[i] = neurons[i]->lb;
			out->output_sup[i] = neurons[i]->ub;
		}
	}	
}

void neuron_fprint(FILE * stream, neuron_t *neuron, char ** name_of_dim){
	//expr_fprint(stream,neuron->expr);
	fprintf(stream,"[%g, %g]\n",-neuron->lb,neuron->ub);
}

void layer_fprint(FILE * stream, layer_t * layer, char** name_of_dim){
	size_t dims = layer->dims;
	size_t i;
	for(i = 0; i < dims; i++){
		fprintf(stream,"neuron: %zu ", i);
		neuron_fprint(stream, layer->neurons[i], name_of_dim);
	}
}



void ffn_handle_last_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias, size_t num_out_neurons, size_t num_in_neurons, size_t *predecessors, bool has_activation, activation_type_t activation, bool alloc, bool use_area_heuristic){
	//printf("last\n");
	//fflush(stdout);
	fppoly_t *fp = fppoly_of_abstract0(element);
	size_t numlayers = fp->numlayers;
    if(alloc){
        if(has_activation){
	   fppoly_add_new_layer(fp,num_out_neurons, FFN, activation);
        }
        else{
           fppoly_add_new_layer(fp,num_out_neurons, FFN, NONE);
        }
    }
	output_abstract_t * out = (output_abstract_t*)malloc(sizeof(output_abstract_t));
	out->output_inf = (double *)malloc(num_out_neurons*sizeof(double)); 
	out->output_sup = (double *)malloc(num_out_neurons*sizeof(double)); 
	out->lexpr = (expr_t **)malloc(num_out_neurons*sizeof(expr_t *));
	out->uexpr = (expr_t **)malloc(num_out_neurons*sizeof(expr_t *));
	fp->out = out;
	neuron_t ** out_neurons = fp->layers[numlayers]->neurons;
	fp->layers[numlayers]->predecessors = predecessors;
	fppoly_internal_t *pr = fppoly_init_from_manager(man, ELINA_FUNID_ASSIGN_LINEXPR_ARRAY);
	size_t i;
	for(i=0; i < num_out_neurons; i++){
		double * weight_i = weights[i];
		double bias_i = bias[i];
		out_neurons[i]->expr = create_dense_expr(weight_i,bias_i,num_in_neurons);
	}
	update_state_using_previous_layers_parallel(man,fp,numlayers,use_area_heuristic);
    if(activation==RELU){
        handle_final_relu_layer(pr,fp->out,out_neurons, num_out_neurons, has_activation);
    }
    else if(activation==SIGMOID){
	handle_final_sigmoid_layer(pr,fp->out,out_neurons, num_out_neurons, has_activation);
    }
    else if(activation==TANH){
	handle_final_tanh_layer(pr,fp->out,out_neurons, num_out_neurons, has_activation);
    }
    
    else{
	for(i=0; i < num_out_neurons; i++){
		out->output_inf[i] = out_neurons[i]->lb;
		out->output_sup[i] = out_neurons[i]->ub;
	}
    }
    //printf("finish\n");
    //fppoly_fprint(stdout,man,fp,NULL);
    //fflush(stdout);
	//layer_fprint(stdout,fp->layers[1],NULL);
	//layer_fprint(stdout,fp->layers[fp->numlayers-1],NULL);
	return;

}

void ffn_handle_last_relu_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_relu, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_relu, RELU, true, use_area_heuristic);
}

void ffn_handle_last_sigmoid_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_sigmoid, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_sigmoid, SIGMOID, true, use_area_heuristic);
}

void ffn_handle_last_tanh_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_tanh, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_tanh, TANH, true, use_area_heuristic);
}

void ffn_handle_last_parabola_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias, size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_parabola, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_parabola, PARABOLA, true,use_area_heuristic);
}

void ffn_handle_last_log_layer(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_log, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_log, LOG, true, use_area_heuristic);
}


void ffn_handle_last_relu_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_relu, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_relu, RELU, false, use_area_heuristic);
}

void ffn_handle_last_sigmoid_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_sigmoid, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_sigmoid, SIGMOID, false, use_area_heuristic);
}

void ffn_handle_last_tanh_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_tanh, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_tanh, TANH, false, use_area_heuristic);
}

void ffn_handle_last_parabola_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias, size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_parabola, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_parabola, PARABOLA, false, use_area_heuristic);
}

void ffn_handle_last_log_layer_no_alloc(elina_manager_t* man, elina_abstract0_t* element, double **weights, double * bias,  size_t num_out_neurons, size_t num_in_neurons, size_t * predecessors, bool has_log, bool use_area_heuristic){
    ffn_handle_last_layer(man, element, weights, bias, num_out_neurons, num_in_neurons, predecessors, has_log, LOG, false, use_area_heuristic);
}



void coeff_to_interval(elina_coeff_t *coeff, double *inf, double *sup){
	double d;
	if(coeff->discr==ELINA_COEFF_SCALAR){
		elina_scalar_t * scalar = coeff->val.scalar;
		d = scalar->val.dbl;
		*inf = -d;
		*sup = d;
	}
	else{
		elina_interval_t *interval = coeff->val.interval;
		d = interval->inf->val.dbl;
		*inf = -d;
		d = interval->sup->val.dbl;
		*sup = d;	
	}
		
}

expr_t * elina_linexpr0_to_expr(elina_linexpr0_t *linexpr0){
	size_t size = linexpr0->size;
	size_t i;
	expr_t *res = (expr_t*)malloc(sizeof(expr_t));
	res->inf_coeff = (double*)malloc(size*sizeof(double));
	res->sup_coeff = (double*)malloc(size*sizeof(double));
	res->size = size;
	if(linexpr0->discr==ELINA_LINEXPR_SPARSE){
		res->type = SPARSE;
		res->dim = (size_t *)malloc(size*sizeof(size_t));
	}
	else{
		res->type = DENSE;
		res->dim = NULL;
	}
	size_t k;
	for(i=0; i< size; i++){
		elina_coeff_t *coeff;
		if(res->type==SPARSE){
			k = linexpr0->p.linterm[i].dim;
			res->dim[i] = k;
			coeff = &linexpr0->p.linterm[i].coeff;
			coeff_to_interval(coeff,&res->inf_coeff[i],&res->sup_coeff[i]);
		}
		else{
		 	k = i;
			coeff = &linexpr0->p.coeff[k];	
			coeff_to_interval(coeff,&res->inf_coeff[k],&res->sup_coeff[k]);
		}
		
	}
	elina_coeff_t *cst = &linexpr0->cst;
	coeff_to_interval(cst,&res->inf_cst,&res->sup_cst);
	return res;
}


elina_interval_t * get_bounds_for_linexpr0(elina_manager_t *man, elina_abstract0_t *element, elina_linexpr0_t *linexpr0, size_t layerno){
	
	elina_interval_t * res = elina_interval_alloc();
	fppoly_t *fp = fppoly_of_abstract0(element);
    fppoly_internal_t *pr = fppoly_init_from_manager(man, ELINA_FUNID_ASSIGN_LINEXPR_ARRAY);
    //printf("start %p %lu\n",fp->layers[layerno],layerno);
    //fflush(stdout);
	expr_t * tmp = elina_linexpr0_to_expr(linexpr0);
    //printf("coming here\n");
    //fflush(stdout);
	double lb = compute_lb_from_expr(pr,tmp,fp,layerno);
	double ub = compute_ub_from_expr(pr,tmp,fp,layerno);
        
    		expr_t *expr = NULL;
	if(fp->layers[layerno]->type==RESIDUAL){
		expr = copy_expr(tmp);
	}
	else{
    		expr = expr_from_previous_layer(pr,tmp, fp->layers[layerno]);
	}
    //printf("end\n");
    //fflush(stdout);
	expr_t * expr2 = copy_expr(expr);
	
	lb = fmin(lb,get_lb_using_previous_layers(man,fp,expr,layerno, true));
	
	ub = fmin(ub,get_ub_using_previous_layers(man,fp,expr2,layerno, true));
	
	elina_interval_set_double(res,-lb,ub);
	free_expr(expr);
	free_expr(expr2);
    	free_expr(tmp);
        //printf("lb: %g ub: %g\n",lb,ub);
        //fflush(stdout);
	return res;
}
     




bool is_greater(elina_manager_t* man, elina_abstract0_t* element, elina_dim_t y, elina_dim_t x, bool use_area_heuristic){
	fppoly_t *fp = fppoly_of_abstract0(element);
	fppoly_internal_t * pr = fppoly_init_from_manager(man,ELINA_FUNID_ASSIGN_LINEXPR_ARRAY);
	if(1){
		
		expr_t * sub = (expr_t *)malloc(sizeof(expr_t));
		//sub->size = size;
		sub->inf_cst = 0;
		sub->sup_cst = 0;
		sub->inf_coeff = (double*)malloc(2*sizeof(double));
		sub->sup_coeff = (double*)malloc(2*sizeof(double));
		sub->dim =(size_t *)malloc(2*sizeof(size_t));
		sub->size = 2;
		sub->type = SPARSE;
		sub->inf_coeff[0] = -1;
		sub->sup_coeff[0] = 1;
		sub->dim[0] = y;
		sub->inf_coeff[1] = 1;
		sub->sup_coeff[1] = -1;
		sub->dim[1] = x;
		
		//layer_fprint(stdout,fp->layers[3],NULL);
		double lb = get_lb_using_previous_layers(man, fp, sub, fp->numlayers, use_area_heuristic);
		
		//free_expr(sub);
		
		if(lb<0){
			return true;
		}
		else{
			return false;
		}
		
	}
	output_abstract_t * out = fp->out;
	expr_t * exprA = out->lexpr[y];
	expr_t * exprB = out->uexpr[x];
	if(exprA==NULL){
		return false;
	}
	else{
		if(exprB==NULL){
			if(out->output_inf[y]<0){
				return true;
			}
			else{
				return false;
			}
			
		}
		else{
			//printf("before access %zu %zu\n", exprA->size,exprB->size);
			//fflush(stdout);
			size_t sizeA = exprA->size;
			size_t sizeB = exprB->size;
			//printf("after access\n");
			//fflush(stdout);
			size_t i,k;
			expr_t * sub = (expr_t *)malloc(sizeof(expr_t));
			//
			//sub->size = size;
			sub->inf_cst = exprA->inf_cst + exprB->sup_cst;
			sub->sup_cst = exprA->sup_cst + exprB->inf_cst;
			//printf("getting here\n");
			//expr_print(exprA);
			//expr_print(exprB);
			//fflush(stdout);
			if(exprA->type==DENSE){
				sub->inf_coeff = (double*)malloc(sizeA*sizeof(double));
				sub->sup_coeff = (double*)malloc(sizeA*sizeof(double));
				sub->dim=NULL;
				sub->size = sizeA;
				sub->type = DENSE;
				if(exprB->type==DENSE){
						for(i=0; i < sizeA; i++){
							sub->inf_coeff[i] = exprA->inf_coeff[i] + exprB->sup_coeff[i];
							sub->sup_coeff[i] = exprA->sup_coeff[i] + exprB->inf_coeff[i];
						} 
				}
				else{
					k = 0;
					for(i=0; i < sizeA; i++){
						if(k < sizeB && exprB->dim[k]==i){
							sub->inf_coeff[i] = exprA->inf_coeff[i] + exprB->sup_coeff[k];
							sub->sup_coeff[i] = exprA->sup_coeff[i] + exprB->inf_coeff[k];
							k++;
						}
						else{
							sub->inf_coeff[i] = exprA->inf_coeff[i];
							sub->sup_coeff[i] = exprA->sup_coeff[i];
						}
					}
				}
				
			}
			else{
				if(exprB->type==DENSE){
					sub->inf_coeff = (double*)malloc(sizeB*sizeof(double));
					sub->sup_coeff = (double*)malloc(sizeB*sizeof(double));
					sub->dim=NULL;
					sub->size = sizeB;
					sub->type = DENSE;
					i = 0;
					for(k=0; k < sizeB; k++){
						if(i < sizeA && exprA->dim[i]==k){
							sub->inf_coeff[k] = exprA->inf_coeff[i] + exprB->sup_coeff[k];
							sub->sup_coeff[k] = exprA->sup_coeff[i] + exprB->inf_coeff[k];
							i++;
						}
						else{
							sub->inf_coeff[i] = exprB->sup_coeff[k];
							sub->sup_coeff[i] = exprB->inf_coeff[k];
						}
					}
				}
				else{
					sub->inf_coeff = (double*)malloc((sizeA+sizeB)*sizeof(double));
					sub->sup_coeff = (double*)malloc((sizeA+sizeB)*sizeof(double));
					sub->dim=NULL;
					
					sub->type = SPARSE;
					size_t l = 0;
					i=0;
					k=0;
					sub->dim = (size_t *)malloc((sizeA+sizeB)*sizeof(size_t));
					while(i < sizeA && k < sizeB){
						if(exprA->dim[i] < exprB->dim[k]){
							sub->inf_coeff[l] = exprA->inf_coeff[i];
							sub->sup_coeff[l] = exprA->sup_coeff[i];
							sub->dim[l] = exprA->dim[i];
							i++;
						
						}
						else if(exprB->dim[k] < exprA->dim[i]){
							sub->inf_coeff[l] = exprB->sup_coeff[k];
							sub->sup_coeff[l] = exprB->inf_coeff[k];
							sub->dim[l] = exprB->dim[k];
							k++;
						}
						else{
							sub->inf_coeff[l] = exprA->inf_coeff[i] + exprB->sup_coeff[k];
							sub->sup_coeff[l] = exprA->sup_coeff[i] + exprB->inf_coeff[k];
							sub->dim[l] = exprA->dim[i];
							i++;
							k++;
						}
						l++;
					}
					while(i < sizeA){
						sub->inf_coeff[l] = exprA->inf_coeff[i];
						sub->sup_coeff[l] = exprA->sup_coeff[i];
						sub->dim[l] = exprA->dim[i];
						i++;
						l++;
					}
					while(k < sizeB){
						sub->inf_coeff[l] = exprB->inf_coeff[k];
						sub->sup_coeff[l] = exprB->sup_coeff[k];
						sub->dim[l] = exprB->dim[k];
						k++;
						l++;
					}
					sub->size = l;
					sub->inf_coeff = (double*)realloc(sub->inf_coeff,l*sizeof(double));
					sub->sup_coeff = (double*)realloc(sub->sup_coeff,l*sizeof(double));
					sub->dim = (size_t *)realloc(sub->dim,l*sizeof(size_t));
				}
			}
			
			//expr_print(sub);
			//fflush(stdout);
			double lb = compute_lb_from_expr(pr,sub,fp,-1);
			//printf("y: %zu x: %zu lb: %g\n",y,x,lb);
			//fflush(stdout);
			free_expr(sub);
			//double lb = -out->output_inf[y] - out->output_sup[x];
			if(lb<0){
				return true;
			}
			else{
				return false;
			}
		}
	}
	
}


long int max(long int a, long int b){
	return a> b? a : b;

}

void conv_handle_first_layer(elina_manager_t *man, elina_abstract0_t *abs, double *filter_weights, double *filter_bias, 
					  size_t *input_size, size_t *filter_size, size_t num_filters, size_t *strides, size_t *output_size, size_t pad_top, size_t pad_left, bool has_bias, size_t * predecessors){
	
	size_t i, j;
	size_t num_pixels = input_size[0]*input_size[1]*input_size[2];

	size_t size = output_size[0]*output_size[1]*output_size[2];
	
	fppoly_internal_t * pr = fppoly_init_from_manager(man,ELINA_FUNID_ASSIGN_LINEXPR_ARRAY);
	fppoly_t *res = fppoly_of_abstract0(abs);
	fppoly_alloc_first_layer(res,size,  CONV, RELU);

	neuron_t ** neurons = res->layers[0]->neurons;
	res->layers[0]->predecessors = predecessors;
	size_t out_x, out_y, out_z;
        size_t inp_x, inp_y, inp_z;
	size_t x_shift, y_shift;


	for(out_x=0; out_x < output_size[0]; out_x++) {
	    for(out_y = 0; out_y < output_size[1]; out_y++) {
		 for(out_z=0; out_z < output_size[2]; out_z++) {
		     size_t mat_x = out_x*output_size[1]*output_size[2] + out_y*output_size[2] + out_z;
		     size_t num_coeff = input_size[2]*filter_size[0]*filter_size[1];
		     size_t actual_coeff = 0;
		     double *coeff = (double *)malloc(num_coeff*sizeof(double));
		     size_t *dim = (size_t *)malloc(num_coeff*sizeof(double));
		     i=0;
		     for(inp_z=0; inp_z <input_size[2]; inp_z++) {
			 for(x_shift = 0; x_shift < filter_size[0]; x_shift++) {
			     for(y_shift =0; y_shift < filter_size[1]; y_shift++) {
				     long int x_val = out_x*strides[0]+x_shift-pad_top;	
			  	     long int y_val = out_y*strides[1]+y_shift-pad_left;
			  	     if(y_val<0 || y_val >= (long int)input_size[1]){
			     			continue;
			  	     }
				     
			  	     if(x_val<0 || x_val >= (long int)input_size[0]){
			     			continue;
			  	     }
				     size_t mat_y = x_val*input_size[1]*input_size[2] + y_val*input_size[2] + inp_z;
				     if(mat_y>=num_pixels){		 
			     			continue;
		          	     } 
				     size_t filter_index = x_shift*filter_size[1]*input_size[2]*output_size[2] + y_shift*input_size[2]*output_size[2] + inp_z*output_size[2] + out_z;
				     coeff[i] = filter_weights[filter_index];
				     dim[i] = mat_y;
				     i++;
				     actual_coeff++;
			     }
			}
		    }
		    double cst = has_bias? filter_bias[out_z] : 0;
	            neurons[mat_x]->expr = create_sparse_expr(coeff,cst,dim,actual_coeff);
		    sort_sparse_expr(neurons[mat_x]->expr);
		  
		
		   neurons[mat_x]->lb = compute_lb_from_expr(pr, neurons[mat_x]->expr,res,-1);
		   neurons[mat_x]->ub = compute_ub_from_expr(pr, neurons[mat_x]->expr,res,-1);
		   free(coeff);
		   free(dim);
	        }
	     }
	}

	
	//printf("return here\n");
	//fppoly_fprint(stdout,man,res,NULL);
	//fflush(stdout);
	return;
}



void conv_handle_intermediate_layer(elina_manager_t* man, elina_abstract0_t* element, double *filter_weights, double * filter_bias,  
				         size_t * input_size, size_t *filter_size, size_t num_filters, size_t *strides, size_t *output_size, size_t pad_top, size_t pad_left, bool has_bias, size_t *predecessors, activation_type_t activation, bool use_area_heuristic){
	//printf("conv intermediate starts here\n");
	//fflush(stdout);
	fppoly_t *fp = fppoly_of_abstract0(element);
	size_t numlayers = fp->numlayers;
	size_t i, j;
	size_t num_pixels = input_size[0]*input_size[1]*input_size[2];
	
	output_size[2] = num_filters;
	size_t num_out_neurons = output_size[0]*output_size[1]*output_size[2];
	//printf("num_out_neurons: %zu %zu\n",num_out_neurons,num_pixels);
	//fflush(stdout);
	fppoly_add_new_layer(fp,num_out_neurons, CONV, activation);
	neuron_t ** out_neurons = fp->layers[numlayers]->neurons;
	fp->layers[numlayers]->predecessors = predecessors;
	size_t out_x, out_y, out_z;
        size_t inp_x, inp_y, inp_z;
	size_t x_shift, y_shift;

	

	for(out_x=0; out_x < output_size[0]; out_x++) {
	    for(out_y = 0; out_y < output_size[1]; out_y++) {
		 for(out_z=0; out_z < output_size[2]; out_z++) {
		     size_t mat_x = out_x*output_size[1]*output_size[2] + out_y*output_size[2] + out_z;
		     size_t num_coeff = input_size[2]*filter_size[0]*filter_size[1];
		     size_t actual_coeff = 0;
		     double *coeff = (double *)malloc(num_coeff*sizeof(double));
		     size_t *dim = (size_t *)malloc(num_coeff*sizeof(double));
		     i=0;
		     for(inp_z=0; inp_z <input_size[2]; inp_z++) {
			 for(x_shift = 0; x_shift < filter_size[0]; x_shift++) {
			     for(y_shift =0; y_shift < filter_size[1]; y_shift++) {
				     long int x_val = out_x*strides[0]+x_shift-pad_top;	
			  	     long int y_val = out_y*strides[1]+y_shift-pad_left;
			  	     if(y_val<0 || y_val >= (long int)input_size[1]){
			     			continue;
			  	     }
				     
			  	     if(x_val<0 || x_val >= (long int)input_size[0]){
			     			continue;
			  	     }
				     size_t mat_y = x_val*input_size[1]*input_size[2] + y_val*input_size[2] + inp_z;
				     if(mat_y>=num_pixels){		 
			     			continue;
		          	     }
				     size_t filter_index = x_shift*filter_size[1]*input_size[2]*output_size[2] + y_shift*input_size[2]*output_size[2] + inp_z*output_size[2] + out_z;
				     coeff[i] = filter_weights[filter_index];
				     dim[i] = mat_y;
				     actual_coeff++;
				     i++;
			     }
			}
		    }
		   double cst = has_bias? filter_bias[out_z] : 0;
	           out_neurons[mat_x]->expr = create_sparse_expr(coeff,cst,dim,actual_coeff);
		   sort_sparse_expr(out_neurons[mat_x]->expr); 
		   free(coeff);
		   free(dim);
	        }
	     }
	}
	
	update_state_using_previous_layers_parallel(man,fp,numlayers,use_area_heuristic);
	
	//printf("return here2\n");
	//fppoly_fprint(stdout,man,fp,NULL);
	//fflush(stdout);
	return;
}

void conv_handle_intermediate_relu_layer(elina_manager_t* man, elina_abstract0_t* element, double *filter_weights, double * filter_bias,  
				         size_t * input_size, size_t *filter_size, size_t num_filters, size_t *strides, size_t *output_size, size_t pad_top, size_t pad_left, bool has_bias, size_t *predecessors, bool use_area_heuristic){

	conv_handle_intermediate_layer(man,element,filter_weights,filter_bias,input_size,filter_size,num_filters,strides, output_size, pad_top, pad_left,has_bias,predecessors,RELU,use_area_heuristic);

}


void conv_handle_intermediate_affine_layer(elina_manager_t* man, elina_abstract0_t* element, double *filter_weights, double * filter_bias,  
				         size_t * input_size, size_t *filter_size, size_t num_filters, size_t *strides, size_t *output_size, size_t pad_top, size_t pad_left, bool has_bias, size_t *predecessors, bool use_area_heuristic){

	conv_handle_intermediate_layer(man,element,filter_weights,filter_bias,input_size,filter_size,num_filters,strides,output_size, pad_top, pad_left, has_bias,predecessors,NONE,use_area_heuristic);

}


void handle_residual_layer(elina_manager_t *man, elina_abstract0_t *element, size_t num_neurons, size_t *predecessors, activation_type_t activation, bool use_area_heuristic){
	fppoly_t * fp = fppoly_of_abstract0(element);
	size_t numlayers = fp->numlayers;
	fppoly_add_new_layer(fp,num_neurons, RESIDUAL, activation);
	fp->layers[numlayers]->predecessors = predecessors;
	size_t i;
	neuron_t **neurons = fp->layers[numlayers]->neurons;
	for(i=0; i < num_neurons; i++){
		double *coeff = (double*)malloc(sizeof(double));
		coeff[0] = 1;
		size_t *dim = (size_t*)malloc(sizeof(size_t));
		dim[0] = i;
		neurons[i]->expr = create_sparse_expr(coeff,0,dim,1);
	}
	update_state_using_previous_layers_parallel(man,fp,numlayers, use_area_heuristic);
}

void handle_residual_relu_layer(elina_manager_t *man, elina_abstract0_t *element, size_t num_neurons, size_t *predecessors, bool use_area_heuristic){
	handle_residual_layer(man,element,num_neurons,predecessors,RELU, use_area_heuristic);
}

void handle_residual_affine_layer(elina_manager_t *man, elina_abstract0_t *element, size_t num_neurons, size_t *predecessors, bool use_area_heuristic){
	handle_residual_layer(man,element,num_neurons,predecessors,NONE, use_area_heuristic);
}

void free_neuron(neuron_t *neuron){
	if(neuron->expr){
		free_expr(neuron->expr);
	}
	if(neuron->lexpr){
		free_expr(neuron->lexpr);
	}
	if(neuron->uexpr){
		free_expr(neuron->uexpr);
	}
	free(neuron);
}

void free_non_lstm_layer_expr(elina_manager_t *man, elina_abstract0_t *abs, size_t layerno){
    fppoly_t *fp = fppoly_of_abstract0(abs);
    if(layerno >= fp->numlayers){
        fprintf(stdout,"the layer does not exist\n");
        return;
    }
    layer_t * layer = fp->layers[layerno];
    size_t dims = layer->dims;
    size_t i;
    for(i=0; i < dims; i++){
        neuron_t *neuron = layer->neurons[i];
        if(neuron->expr){
            free_expr(neuron->expr);
        }
        if(neuron->lexpr){
            free_expr(neuron->lexpr);
        }
        if(neuron->uexpr){
            free_expr(neuron->uexpr);
        }
    }
}

void layer_free(layer_t * layer){
	size_t dims = layer->dims;
	size_t i;
	for(i=0; i < dims; i++){
		free_neuron(layer->neurons[i]);
	}
	free(layer->neurons);
	layer->neurons = NULL;
	if(layer->h_t_inf!=NULL){
		free(layer->h_t_inf);
		layer->h_t_inf = NULL;
	}

	if(layer->h_t_sup!=NULL){
		free(layer->h_t_sup);
		layer->h_t_sup = NULL;
	}
	
	if(layer->c_t_inf!=NULL){
		free(layer->c_t_inf);
		layer->c_t_inf = NULL;
	}

	if(layer->c_t_sup!=NULL){
		free(layer->c_t_sup);
		layer->c_t_sup = NULL;
	}

	free(layer);
	layer = NULL;
}



void fppoly_free(elina_manager_t *man, fppoly_t *fp){
	size_t i;
	size_t output_size = fp->layers[fp->numlayers-1]->dims;
	for(i=0; i < fp->numlayers; i++){
		layer_free(fp->layers[i]);
	}
	
	for(i=0; i < output_size; i++){
		if(fp->out->lexpr[i]){
			free_expr(fp->out->lexpr[i]);
		}
		if(fp->out->uexpr[i]){
			free_expr(fp->out->uexpr[i]);
		}
	}
	
	free(fp->layers);
	fp->layers = NULL;
	free(fp->input_inf);
	fp->input_inf = NULL;
        if(fp->input_lexpr!=NULL && fp->input_uexpr!=NULL){
		for(i=0; i < fp->num_pixels; i++){
			free(fp->input_lexpr[i]);
			free(fp->input_uexpr[i]);
		}
	
		free(fp->input_lexpr);
		fp->input_lexpr = NULL;
		free(fp->input_uexpr);
		fp->input_uexpr = NULL;
        }
	free(fp->input_sup);
	fp->input_sup = NULL;
	free(fp->out->output_inf);
	fp->out->output_inf = NULL;
	free(fp->out->output_sup);
	fp->out->output_sup = NULL;
	free(fp->out->lexpr);
	fp->out->lexpr = NULL;
	free(fp->out->uexpr);
	fp->out->uexpr = NULL;
	free(fp->out);
	fp->out=NULL;
	free(fp);
	fp = NULL;
}






void fppoly_fprint(FILE* stream, elina_manager_t* man, fppoly_t* fp, char** name_of_dim){
	size_t i;
	for(i = 0; i < fp->numlayers; i++){
		fprintf(stream,"layer: %zu\n", i);
		layer_fprint(stream, fp->layers[i], name_of_dim);
	}
	size_t output_size = fp->layers[fp->numlayers-1]->dims;
	if(fp->out!=NULL){
		fprintf(stream,"OUTPUT bounds: \n");
		for(i=0; i < output_size;i++){
			fprintf(stream,"%zu: [%g,%g] \n",i,-fp->out->output_inf[i],fp->out->output_sup[i]);
		}
	}
}


elina_interval_t * box_for_neuron(elina_manager_t* man, elina_abstract0_t * abs, size_t layerno, size_t neuron_no){
	fppoly_t *fp = fppoly_of_abstract0(abs);
	if(layerno >= fp->numlayers){
		fprintf(stdout,"the layer does not exist\n");
		return NULL;
	}
	layer_t * layer = fp->layers[layerno];
	size_t dims = layer->dims;
	if(neuron_no >= dims){
		fprintf(stdout,"the neuron does not exist\n");
		return NULL;
	}
	neuron_t * neuron = layer->neurons[neuron_no];
	elina_interval_t * res = elina_interval_alloc();
	elina_interval_set_double(res,-neuron->lb,neuron->ub);
	return res;
}

elina_interval_t ** box_for_layer(elina_manager_t* man, elina_abstract0_t * abs, size_t layerno){
	fppoly_t *fp = fppoly_of_abstract0(abs);
	if(layerno >= fp->numlayers){
		fprintf(stdout,"the layer does not exist\n");
		return NULL;
	}
	layer_t * layer = fp->layers[layerno];
	size_t dims = layer->dims;
	elina_interval_t ** itv_arr = (elina_interval_t **)malloc(dims*sizeof(elina_interval_t *));
	size_t i;
	for(i=0; i< dims; i++){
		itv_arr[i] = box_for_neuron(man, abs, layerno, i);
		
	}
	return itv_arr;
}


size_t get_num_neurons_in_layer(elina_manager_t* man, elina_abstract0_t * abs, size_t layerno){
	fppoly_t *fp = fppoly_of_abstract0(abs);
	if(layerno >= fp->numlayers){
		fprintf(stdout,"the layer does not exist\n");
		return 0;
	}
	layer_t * layer = fp->layers[layerno];
	size_t dims = layer->dims;
	
	return dims;
}

elina_linexpr0_t * get_expr_for_output_neuron(elina_manager_t *man, elina_abstract0_t *abs, size_t i, bool is_lower){
	fppoly_internal_t *pr = fppoly_init_from_manager(man, ELINA_FUNID_ASSIGN_LINEXPR_ARRAY);
	fppoly_t *fp = fppoly_of_abstract0(abs);
	
	size_t output_size = fp->layers[fp->numlayers-1]->dims;
	if(i >= output_size){
		return NULL;
	}
	size_t num_pixels = fp->num_pixels;
	expr_t * expr = NULL;
	if(is_lower){
		expr = fp->out->lexpr[i];
	}
	else{
		expr = fp->out->uexpr[i];
	}
	elina_linexpr0_t * res = NULL;
	size_t j,k;
	if((fp->input_lexpr!=NULL) && (fp->input_uexpr!=NULL)){
		if(is_lower){
			expr =  replace_input_poly_cons_in_lexpr(pr, expr, fp);
		}
		else{
			expr =  replace_input_poly_cons_in_uexpr(pr, expr, fp);
		}
	}
	size_t expr_size = expr->size;
	if(expr->type==SPARSE){
		sort_sparse_expr(expr);
		res = elina_linexpr0_alloc(ELINA_LINEXPR_SPARSE,expr_size);
	}
	else{
		res = elina_linexpr0_alloc(ELINA_LINEXPR_DENSE,expr_size);
	}
	elina_linexpr0_set_cst_interval_double(res,-expr->inf_cst,expr->sup_cst);
	
	for(j=0;j < expr_size; j++){
		if(expr->type==DENSE){
			k = j;
		}
		else{
			k = expr->dim[j];
		}
		elina_linexpr0_set_coeff_interval_double(res,k,-expr->inf_coeff[j],expr->sup_coeff[j]);
	}
	if((fp->input_lexpr!=NULL) && (fp->input_uexpr!=NULL)){
		free_expr(expr);
	}
	return res;
}

elina_linexpr0_t * get_lexpr_for_output_neuron(elina_manager_t *man,elina_abstract0_t *abs, size_t i){
	return get_expr_for_output_neuron(man,abs,i, true);
}

elina_linexpr0_t * get_uexpr_for_output_neuron(elina_manager_t *man,elina_abstract0_t *abs, size_t i){
	return get_expr_for_output_neuron(man,abs,i, false);
}

void update_bounds_for_neuron(elina_manager_t *man, elina_abstract0_t *abs, size_t layerno, size_t neuron_no, double lb, double ub){
	fppoly_t *fp = fppoly_of_abstract0(abs);
	if(layerno >= fp->numlayers){
		fprintf(stdout,"the layer does not exist\n");
		return;
	}
	layer_t * layer = fp->layers[layerno];
	neuron_t * neuron = layer->neurons[neuron_no];
	neuron->lb = -lb;
	neuron->ub = ub;
}
